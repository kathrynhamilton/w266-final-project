{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to assess precision, recall, fscore\n",
    "def assess_accuracy(label_jsonl, predict_jsonl):\n",
    "    \n",
    "    # import and merge into one dataframe, dropping bad ground truth rows\n",
    "    label = pd.read_json(label_jsonl, lines=True)\n",
    "    predict = pd.read_json(predict_jsonl, lines=True)\n",
    "    merged = pd.merge(predict, label, how='inner',on=['text'])\n",
    "    merged = merged[merged.answer_y=='accept']\n",
    "    \n",
    "    # go through and extract each word from each recipe into two dataframes, one for annotated, one for original\n",
    "    label_words = pd.DataFrame()\n",
    "    predict_words = pd.DataFrame()\n",
    "    for index,row in merged.iterrows():\n",
    "        label_data = row['spans_y']\n",
    "        predict_data = row['spans_x']\n",
    "        for item in label_data:\n",
    "            label_words = label_words.append([[index,item]],ignore_index=True)\n",
    "        for item in predict_data:\n",
    "            predict_words = predict_words.append([[index,item]],ignore_index=True)\n",
    "    \n",
    "    # get json formatted stuff out and into its own columns\n",
    "    label_words.columns = ['recipe_index','json']\n",
    "    predict_words.columns = ['recipe_index','json']\n",
    "    label_words = pd.concat([label_words.drop(['json'],axis=1), label_words['json'].apply(pd.Series)],axis=1)\n",
    "    label_words = label_words.drop(['token_start','token_end'],axis=1)\n",
    "    predict_words = pd.concat([predict_words.drop(['json'],axis=1), predict_words['json'].apply(pd.Series)],axis=1)\n",
    "    \n",
    "    # true positives, correctly predicted the right class\n",
    "    TP_df = pd.merge(label_words,predict_words, on=['recipe_index','start','end','label'],how='inner')\n",
    "    TP = len(TP_df.index)\n",
    "    \n",
    "    # false positives, predicted a class where there is no class, or predicted the wrong class\n",
    "    label_remain = pd.concat([label_words,TP_df],axis=0).drop_duplicates(keep=False)\n",
    "    predict_remain = pd.concat([predict_words,TP_df],axis=0).drop_duplicates(keep=False)\n",
    "    \n",
    "    dc_df = pd.concat([label_remain,predict_remain])  # different class, same start and end\n",
    "    dc_df = dc_df[dc_df.duplicated(['recipe_index','start','end'], keep=False)]\n",
    "    dc = len(dc_df.index)/2\n",
    "    \n",
    "    label_remain = pd.concat([label_remain,dc_df,dc_df],axis=0).drop_duplicates(keep=False)\n",
    "    predict_remain = pd.concat([predict_remain,dc_df,dc_df],axis=0).drop_duplicates(keep=False)\n",
    "    \n",
    "    ss_df = pd.concat([label_remain,predict_remain])  # same start position\n",
    "    ss_df = ss_df[ss_df.duplicated(['recipe_index','start'],keep=False)]\n",
    "    ss = len(ss_df.index)/2\n",
    "    \n",
    "    label_remain = pd.concat([label_remain,ss_df,ss_df],axis=0).drop_duplicates(keep=False)\n",
    "    predict_remain = pd.concat([predict_remain,ss_df,ss_df],axis=0).drop_duplicates(keep=False)\n",
    "    \n",
    "    se_df = pd.concat([label_remain,predict_remain])  # same end position\n",
    "    se_df = se_df[se_df.duplicated(['recipe_index','end'],keep=False)]\n",
    "    se = len(se_df.index)/2\n",
    "    \n",
    "    label_remain = pd.concat([label_remain,se_df,se_df],axis=0).drop_duplicates(keep=False)\n",
    "    predict_remain = pd.concat([predict_remain,se_df,se_df],axis=0).drop_duplicates(keep=False)\n",
    "    \n",
    "    # predicted wrong class = predicted different class + same start but different end + same end but different start\n",
    "    pwc = dc + ss + se\n",
    "    \n",
    "    FP = len(predict_remain.index) + pwc\n",
    "    \n",
    "    #false negatives, did not predict anything when should have\n",
    "    FN = len(label_remain.index)\n",
    "    \n",
    "    \n",
    "    #final calculations\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1_score = 2*(recall*precision)/(recall+precision)\n",
    "    \n",
    "    print('precision',precision)\n",
    "    print('recall',recall)\n",
    "    print('f1_score',f1_score)\n",
    "    \n",
    "    return merged, label_words, predict_words, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original seed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.814218009478673\n",
      "recall 0.5241000610128127\n",
      "f1_score 0.637713437268003\n"
     ]
    }
   ],
   "source": [
    "annotated_test = '../KH_Data/test_2_epicurious_KH_annotated.jsonl'\n",
    "\n",
    "# original seed words\n",
    "original_test = '../KH_Data/test_2_epicurious_KH_original.jsonl'\n",
    "\n",
    "[merged, label_words, predict_words, precision, recall, f1_score] = assess_accuracy(annotated_test, original_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### boosted seed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.7704081632653061\n",
      "recall 0.5770700636942675\n",
      "f1_score 0.6598689002184996\n"
     ]
    }
   ],
   "source": [
    "annotated_test = '../KH_Data/test_2_epicurious_KH_annotated.jsonl'\n",
    "\n",
    "# boosted seed words\n",
    "original_test = '../KH_Data/test_2_epicurious_KP_original_annot2.jsonl'\n",
    "\n",
    "[merged, label_words, predict_words, precision, recall, f1_score] = assess_accuracy(annotated_test, original_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
